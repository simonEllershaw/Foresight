{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bbeaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5ba9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.handlers.clear()\n",
    "log.addHandler(logging.StreamHandler())\n",
    "log.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bc409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foresight.datasets.data_collator import CollataAndPad\n",
    "\n",
    "from foresight.utils import pickle\n",
    "from foresight.tokenizers.simple_map_tokenizer import SimpleMapTokenizer\n",
    "# from medcat.cdb import CDB\n",
    "from foresight.datasets.data_collator import CollataAndPad\n",
    "from foresight.metrics.next_concept_prediction import precision, metrics_data2df, ComputePrecisionHF\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "# from medcat.cat import CAT\n",
    "# from foresight.models.lucid_transformers import LucidLM2HF\n",
    "from transformers import SchedulerType\n",
    "\n",
    "from datasets import Dataset\n",
    "import math\n",
    "import datasets\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from foresight.tokenizers import PreTrainedTokenizerFastWithPositionIDPadding\n",
    "from foresight.datasets.data_collator_v2 import DataCollatorForLanguageModelingMaskStaticVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394581c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8580feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path.cwd() / \"outputs\"\n",
    "SAVE_TOKENIZER_PATH = OUTPUT_DIR / \"tokenizer\"\n",
    "SAVE_ENCODED_DATASET_PATH = OUTPUT_DIR / \"encoded_dataset\"\n",
    "MODEL_LOGS_DIR = OUTPUT_DIR / \"model_logs\" / time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "NUM_STATIC_VARIABLES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdb26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = datasets.load_from_disk(SAVE_ENCODED_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb8fb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFastWithPositionIDPadding.from_pretrained(SAVE_TOKENIZER_PATH)\n",
    "data_collator = DataCollatorForLanguageModelingMaskStaticVariables(tokenizer=tokenizer, mlm=False, num_static_variables=NUM_STATIC_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d394ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position_ids': tensor([[ 0,  0,  0,  1,  1,  2,  3,  3,  4,  5,  5,  6,  7,  7,  8,  9,  9, 10,\n",
       "         11, 11, 12, 13, 13, 14, 15, 15, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,\n",
       "          6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11,\n",
       "         12, 12, 12, 13, 13, 13]]), 'input_ids': tensor([[33, 21, 25,  2, 10,  2,  2,  9,  2,  2,  3,  2,  2,  7,  2,  2,  5,  2,\n",
       "          2,  4,  2,  2,  8,  2,  2,  6,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1],\n",
       "        [35, 21, 26,  2, 34, 32,  2, 30, 31,  2, 28, 29,  2, 23, 24,  2, 18, 22,\n",
       "          2, 10, 19,  2,  9, 11,  2,  3, 14,  2,  7, 16,  2,  5, 12,  2,  4, 15,\n",
       "          2,  8, 17,  2,  6, 13]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[-100, -100, -100,    2,   10,    2,    2,    9,    2,    2,    3,    2,\n",
       "            2,    7,    2,    2,    5,    2,    2,    4,    2,    2,    8,    2,\n",
       "            2,    6,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100],\n",
       "        [-100, -100, -100,    2,   34,   32,    2,   30,   31,    2,   28,   29,\n",
       "            2,   23,   24,    2,   18,   22,    2,   10,   19,    2,    9,   11,\n",
       "            2,    3,   14,    2,    7,   16,    2,    5,   12,    2,    4,   15,\n",
       "            2,    8,   17,    2,    6,   13]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = DataLoader(\n",
    "    encoded_dataset[\"train\"], batch_size=2, shuffle=False, collate_fn=data_collator\n",
    ")\n",
    "next(iter(dataset_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22d32c",
   "metadata": {},
   "source": [
    "# Create GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cc7f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a new model\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size + 10,\n",
    "    # n_positions=16,\n",
    "    # n_embd=16,\n",
    "    # n_layer=2,\n",
    "    # n_head=2,\n",
    "    bos_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47241c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d72b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44bb408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wpe.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae533a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wpe.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d4d747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"position_ids\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ee1ea",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28e17497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute_metrics = ComputePrecisionHF(tokenizer.id2tkn, \n",
    "#                                      prediction_scope='time_range', \n",
    "#                                      topk=1, \n",
    "#                                      start=0, \n",
    "#                                      return_all_metrics=False, \n",
    "#                                      batch_size=1000, \n",
    "#                                      select_token_types=all_types,\n",
    "#                                      type_data=test_set_to_use['token_type'],\n",
    "#                                      token_type2tokens=tokenizer.token_type2tokens,\n",
    "#                                      time_data=test_set_to_use['time'], \n",
    "#                                      time_range=30*24*60*60,\n",
    "#                                      ignore_label_status=False,\n",
    "#                                      min_time_left=24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974a735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_LOGS_DIR,          # output directory\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    weight_decay=1e-2,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    warmup_ratio=0.01,\n",
    "    learning_rate= 3.14e-04,\n",
    "    eval_accumulation_steps=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    # metric_for_best_model='eval_loss',\n",
    "    \n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=SchedulerType.LINEAR,\n",
    "    # use_cpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e25889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c2b1847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wandb.init(project='timecat', entity='wish', name=RUN_NAME + '-gpt-16-16_1day_no_base_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f0c996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=encoded_dataset['train'],         # training dataset\n",
    "    eval_dataset=encoded_dataset['test'],             # evaluation dataset\n",
    "    # compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    # prediction_loss_only=True\n",
    "    # tokenizer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c7ed86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:35, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.654330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.690882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.631073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.623425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.437474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.424219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.383392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.375720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.376614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=3.148661804199219, metrics={'train_runtime': 37.5288, 'train_samples_per_second': 213.17, 'train_steps_per_second': 0.799, 'total_flos': 188767162368000.0, 'train_loss': 3.148661804199219, 'epoch': 9.6})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "647efb10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[43mMODEL_PATH\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.save_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967599dd",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = set(['T-11', 'T-45', 'T-55', 'T-18', 'T-26', 'T-40', 'T-39', 'T-49', 'T-29', 'T-34', \n",
    "                 'T-9', 'T-33', 'T-44', 'T-6', 'T-27', 'T-38', 'T-35', 'T-3', 'T-58'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67dd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_to_use = encoded_dataset['test']\n",
    "test_set_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=None,         # training dataset\n",
    "    eval_dataset=None,             # evaluation dataset\n",
    "    compute_metrics=None,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ec628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(metrics_data=None, test_set_to_use=None, trainer=None, m_file=None, f_name=None):\n",
    "    size = 1000\n",
    "    for i in range(int(math.ceil(len(test_set_to_use) / size))):\n",
    "        _dataset = Dataset.from_dict(test_set_to_use[i*size:(i+1)*size])\n",
    "        compute_metrics.time_data = _dataset['time']\n",
    "        compute_metrics.type_data = _dataset['token_type']\n",
    "        if len(_dataset):\n",
    "            p = trainer.predict(_dataset)\n",
    "            metrics_data = compute_metrics(p, metrics_data)['metrics_data']\n",
    "    m_file.write(\"{}, {}, {}, {}\\n\".format(f_name, metrics_data['precision']['all'], \n",
    "                                 metrics_data['precision']['new'], \n",
    "                                 metrics_data['precision']['old'],\n",
    "                                 metrics_data['recall']['all'],\n",
    "                                 metrics_data['recall']['new'],\n",
    "                                 metrics_data['recall']['old']))\n",
    "    print(f_name,\n",
    "          metrics_data['precision']['all'], \n",
    "          metrics_data['precision']['new'], \n",
    "          metrics_data['precision']['old'],\n",
    "          metrics_data['recall']['all'],\n",
    "          metrics_data['recall']['new'],\n",
    "          metrics_data['recall']['old']) \n",
    "    pickle.dump(metrics_data, f_name)\n",
    "\n",
    "    return metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aee33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_file = open(\"./metrics/summary.txt\", 'w', buffering=1)\n",
    "m_file.write(\"file_name, precision all, precision new, precision old\\n\")\n",
    "\n",
    "for types in [all_types, {'T-11'}, {'T-55'}, {'T-18'}, {'T-39'}]:\n",
    "    _types = list(types)[0] if len(types) == 1 else 'all_types'\n",
    "    for timerange in [30, 365, 1000000]:\n",
    "        compute_metrics = ComputePrecisionHF(tokenizer.id2tkn, \n",
    "                                         prediction_scope='time_range', \n",
    "                                         topk=1, # 1, 5, 10\n",
    "                                         start=0, # 0, 10, 20, 50, 100\n",
    "                                         return_all_metrics=True, \n",
    "                                         batch_size=1000, \n",
    "                                         select_token_types=types,\n",
    "                                         type_data=test_set_to_use['token_type'],\n",
    "                                         token_type2tokens=tokenizer.token_type2tokens,\n",
    "                                         time_data=test_set_to_use['time'], \n",
    "                                         time_range=timerange*24*60*60, #30, 365, 1000000\n",
    "                                         ignore_label_status=False,\n",
    "                                         min_time_left=24*60*60)\n",
    "        f_name = f\"./metrics/start-0_topk-1_time_range-{timerange}_types-{_types}.pickle\"\n",
    "        get_metrics(None, test_set_to_use, trainer, m_file, f_name)\n",
    "\n",
    "    for topk in [5, 10]:\n",
    "        compute_metrics = ComputePrecisionHF(tokenizer.id2tkn, \n",
    "                                         prediction_scope='time_range', \n",
    "                                         topk=topk, # 1, 5, 10\n",
    "                                         start=0, # 0, 10, 20, 50, 100\n",
    "                                         return_all_metrics=True, \n",
    "                                         batch_size=1000, \n",
    "                                         select_token_types=types,\n",
    "                                         type_data=test_set_to_use['token_type'],\n",
    "                                         token_type2tokens=tokenizer.token_type2tokens,\n",
    "                                         time_data=test_set_to_use['time'], \n",
    "                                         time_range=30*24*60*60, #30, 365, 1000000\n",
    "                                         ignore_label_status=False,\n",
    "                                         min_time_left=24*60*60)\n",
    "        f_name = f\"./metrics/start-0_topk-{topk}_time_range-30_types-{_types}.pickle\"\n",
    "        get_metrics(None, test_set_to_use, trainer, m_file, f_name)\n",
    "m_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75db95",
   "metadata": {},
   "source": [
    "# Test Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = set(['death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=None,         # training dataset\n",
    "    eval_dataset=None,             # evaluation dataset\n",
    "    compute_metrics=None,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebabb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(metrics_data=None, test_set_to_use=None, trainer=None, m_file=None, f_name=None):\n",
    "    size = 1000\n",
    "    for i in range(int(math.ceil(len(test_set_to_use) / size))):\n",
    "        _dataset = Dataset.from_dict(test_set_to_use[i*size:(i+1)*size])\n",
    "        compute_metrics.time_data = _dataset['time']\n",
    "        compute_metrics.type_data = _dataset['token_type']\n",
    "        if len(_dataset):\n",
    "            p = trainer.predict(_dataset)\n",
    "            metrics_data = compute_metrics(p, metrics_data)['metrics_data']\n",
    "    m_file.write(\"{}, {}, {}, {}\\n\".format(f_name, metrics_data['precision']['all'], \n",
    "                                 metrics_data['precision']['new'], \n",
    "                                 metrics_data['precision']['old']))\n",
    "    print(f_name,\n",
    "          metrics_data['precision']['all'], \n",
    "          metrics_data['precision']['new'], \n",
    "          metrics_data['precision']['old'])\n",
    "    pickle.dump(metrics_data, f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = ComputePrecisionHF(tokenizer.id2tkn, \n",
    "                                 topk=1, # 1, 5, 10\n",
    "                                 start=0, # 0, 10, 20, 50, 100\n",
    "                                 return_all_metrics=True, \n",
    "                                 batch_size=1000, \n",
    "                                 type_data=test_set_to_use['token_type'],\n",
    "                                 token_type2tokens=tokenizer.token_type2tokens,\n",
    "                                 time_data=test_set_to_use['time'], \n",
    "                                 time_range=24*60*60, #30, 365, 1000000\n",
    "                                 ignore_label_status=False,\n",
    "                                 min_time_left=0,\n",
    "                                 concept_id=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71282b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = None\n",
    "_dataset = Dataset.from_dict(test_set_to_use[0:1000])\n",
    "compute_metrics.time_data = _dataset['time']\n",
    "compute_metrics.type_data = _dataset['token_type']\n",
    "if len(_dataset):\n",
    "    p = trainer.predict(_dataset)\n",
    "    metrics_data = compute_metrics(p, metrics_data)['metrics_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b85a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c716a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tkn2id['The patient has died']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(_dataset['input_ids'])):\n",
    "    if 270 in _dataset['input_ids'][i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb8e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_data = None\n",
    "size = 1000\n",
    "for i in range(int(math.ceil(len(test_set_to_use) / size))):\n",
    "    _dataset = Dataset.from_dict(test_set_to_use[i*size:(i+1)*size])\n",
    "    compute_metrics.time_data = _dataset['time']\n",
    "    compute_metrics.type_data = _dataset['token_type']\n",
    "    if len(_dataset):\n",
    "        p = trainer.predict(_dataset)\n",
    "        metrics_data = compute_metrics(p, metrics_data)['metrics_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f6a43",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter \n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = ComputePrecisionHF(id2tkn, id2type, prediction_scope='age', topk=1, start=0, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 20\n",
    "N_GPU_PER_TRIAL = 1\n",
    "METRIC_TO_OPTIMIZE = 'eval_precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27783bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    torch.cuda.empty_cache()\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    \n",
    "    config = GPT2Config(\n",
    "        vocab_size=len(embeddings),\n",
    "        n_positions=MAX_SEQ_LEN+1,\n",
    "        n_ctx=MAX_SEQ_LEN+1,\n",
    "        n_embd=params.get('n_embd', 300),\n",
    "        n_layer=params.get('n_layer', 1),\n",
    "        n_head=params.get('n_head', 1),\n",
    "        bos_token_id=tkn2id['<PAD>'],\n",
    "        eos_token_id=tkn2id['<PAD>']\n",
    "    )\n",
    "    model = GPT2LMHeadModel(config)\n",
    "    \n",
    "    if params.get('load_weights', 0):\n",
    "        model.transformer.wte.load_state_dict({'weight': torch.tensor(embeddings, dtype=torch.float32)})\n",
    "        model.transformer.wte.weight.requires_grad = True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=128,   # batch size for evaluation\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=200,\n",
    "    eval_steps=200,\n",
    "    learning_rate= 5e-5,\n",
    "    eval_accumulation_steps=1,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy='steps',\n",
    "    skip_memory_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.n_head = 1\n",
    "training_args.n_layer = 1\n",
    "training_args.n_embd = 300\n",
    "training_args.load_weights = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_dataset = encoded_dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f111f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_train_dataset = tune_dataset['train']\n",
    "tune_test_dataset = tune_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "#    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=tune_train_dataset,         # training dataset\n",
    "    eval_dataset=tune_test_dataset,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    "    model_init=get_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0356cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_config = {\n",
    "    \"num_train_epochs\": tune.choice([5]),\n",
    "    \"n_head\": tune.choice([2, 4, 6]),\n",
    "}\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=METRIC_TO_OPTIMIZE,\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=1,\n",
    "    hyperparam_mutations={\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
    "        \"per_device_train_batch_size\": [16, 32, 64, 128],\n",
    "        \"n_layer\": tune.choice([2, 4, 6, 8]),\n",
    "#       \"n_embd\": tune.choice([256, 512]),\n",
    "        \"load_weights\": tune.choice([0, 1]),\n",
    "        \"warmup_steps\": tune.choice([20, 40, 60, 100]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def compute_objective(metrics):\n",
    "    metrics = copy.deepcopy(metrics)\n",
    "    eval_precision = metrics.pop('eval_precision')\n",
    "    \n",
    "    return eval_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5bff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = trainer.hyperparameter_search(\n",
    "    hp_space=lambda _: tune_config,\n",
    "    backend=\"ray\",\n",
    "    n_trials=NUM_TRIALS,\n",
    "    direction='maximize',\n",
    "    compute_objective=compute_objective,\n",
    "    resources_per_trial={\n",
    "        \"cpu\": 1,\n",
    "        \"gpu\": N_GPU_PER_TRIAL\n",
    "    },\n",
    "    scheduler=scheduler,\n",
    "    keep_checkpoints_num=1,\n",
    "    checkpoint_score_attr=METRIC_TO_OPTIMIZE,\n",
    "    stop=None,\n",
    "    local_dir=RESULTS_HYPERPARAM,\n",
    "    name=\"21_May_2021\",\n",
    "    log_to_file=False,\n",
    "    loggers=None,# (WandbLogger, ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3fae5",
   "metadata": {},
   "source": [
    "# Saliency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b237de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ecco.LM(trainer.model, tokenizer, model_name='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad3750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = 49\n",
    "print(\"~~\".join([tokenizer.id2tkn[id] for id in encoded_dataset['test'][ind]['input_ids']]))\n",
    "text = \"~~\".join([tokenizer.id2tkn[id] for id in encoded_dataset['test'][ind]['input_ids'][1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28108d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = lm.generate(text, generate=10, do_sample=True, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b3898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.saliency(style=\"detailed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb6cf5",
   "metadata": {},
   "source": [
    "# Probability prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foresight.sight import Sight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sight = Sight(tokenizer=tokenizer, device='cuda', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb.name2cuis['muscle~pain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb.get_name('pain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<ETHNICITY>~~White~~<SEX>~~Male~~<AGE>~~23~~49727002~~386661006'.split(\"~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fc62e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Small with WD\n",
    "r = sight.next_concepts(text, type_ids=['T-11'], n=40, p_new=True, create_position_ids=False)\n",
    "print([cdb.get_name(x) for x in text])\n",
    "for x in r:\n",
    "    print(x[0], x[1], cdb.get_name(x[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
