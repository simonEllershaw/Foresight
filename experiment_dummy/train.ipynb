{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fa6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "log = logging.getLogger()\n",
    "log.handlers.clear()\n",
    "log.addHandler(logging.StreamHandler())\n",
    "log.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datasets import Dataset\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from medcat.cat import CAT\n",
    "# from foresight.models.lucid_transformers import LucidLM2HF\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    SchedulerType,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "# from medcat.cdb import CDB\n",
    "from foresight.datasets.data_collator import CollataAndPad\n",
    "from foresight.datasets.data_collator_v2 import (\n",
    "    DataCollatorForLanguageModelingMaskStaticVariables,\n",
    ")\n",
    "from foresight.metrics.next_concept_prediction import (\n",
    "    ComputePrecisionHF,\n",
    "    metrics_data2df,\n",
    "    precision,\n",
    ")\n",
    "from foresight.metrics.timeline import TimelineMetrics\n",
    "from foresight.models.custom_GPT2 import CustomGPT2Config, CustomGPT2LMHeadModel\n",
    "from foresight.tokenizers import PreTrainedTokenizerFastWithPositionIDPadding\n",
    "from foresight.tokenizers.simple_map_tokenizer import SimpleMapTokenizer\n",
    "from foresight.utils import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394581c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path.cwd() / \"outputs\"\n",
    "SAVE_TOKENIZER_PATH = OUTPUT_DIR / \"tokenizer\"\n",
    "SAVE_ENCODED_DATASET_PATH = OUTPUT_DIR / \"encoded_dataset\"\n",
    "MODEL_LOGS_DIR = OUTPUT_DIR / \"model_logs\" / time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "FINAL_MODEL_DIR = MODEL_LOGS_DIR / \"final_model\"\n",
    "MODEL_LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_STATIC_VARIABLES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = datasets.load_from_disk(SAVE_ENCODED_DATASET_PATH)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFastWithPositionIDPadding.from_pretrained(\n",
    "    SAVE_TOKENIZER_PATH\n",
    ")\n",
    "training_data_collator = DataCollatorForLanguageModelingMaskStaticVariables(\n",
    "    tokenizer=tokenizer, mlm=False, num_static_variables=NUM_STATIC_VARIABLES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22d32c",
   "metadata": {},
   "source": [
    "# Create GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"n_layer_and_heads\": tune.choice([2, 4, 8, 16, 32, 64]),\n",
    "# \"embed_dim\": tune.choice([256, 512]),\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    params: dict[str, Any],\n",
    "    tokenizer: PreTrainedTokenizerFastWithPositionIDPadding,\n",
    "    max_sequence_length: int,\n",
    "):\n",
    "    print(\"get_model\", params)\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    config = CustomGPT2Config(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        n_positions=max_sequence_length,\n",
    "        n_ctx=max_sequence_length,\n",
    "        # n_embd=params.get('n_embd', 512),\n",
    "        n_layer=params.get(\"n_layer_and_heads\", 4),\n",
    "        n_head=params.get(\"n_layer_and_heads\", 4),\n",
    "        bos_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.pad_token_id,\n",
    "        sep_token_id=tokenizer.sep_token_id,\n",
    "    )\n",
    "    return CustomGPT2LMHeadModel(config)\n",
    "\n",
    "\n",
    "max_sequence_length = math.ceil(\n",
    "    max(len(sample[\"input_ids\"]) for sample in encoded_dataset[\"train\"]) * 1.2\n",
    ")\n",
    "get_model_lambda = lambda params: get_model(params, tokenizer, max_sequence_length)\n",
    "trial_model = get_model_lambda(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in trial_model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113550ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dataset = DataLoader(\n",
    "    encoded_dataset[\"train\"],\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=training_data_collator,\n",
    ")\n",
    "batch = next(iter(trial_dataset))\n",
    "trial_model(**{k: v for k, v in batch.items()}).logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ee1ea",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus_per_trial = 1\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_LOGS_DIR,  # output directory\n",
    "    no_cuda=gpus_per_trial <= 0,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_device_train_batch_size=32,  # config\n",
    "    warmup_ratio=0.1,  # config\n",
    "    weight_decay=0.1,  # config\n",
    "    logging_dir=\"./logs\",\n",
    "    skip_memory_metrics=True,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective(metrics):\n",
    "    metrics = copy.deepcopy(metrics)\n",
    "    return metrics.pop(\"eval_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeline_metrics = TimelineMetrics(tokenizer)\n",
    "# compute_metrics = lambda eval_preds: timeline_metrics.batch_compute_precision_recall_f1(\n",
    "#     eval_preds, batch_size = 100\n",
    "# )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=get_model_lambda,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    data_collator=training_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_config = {\n",
    "    \"per_device_train_batch_size\": tune.choice([16, 32, 64, 128]),\n",
    "}\n",
    "\n",
    "pbt_scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"eval_loss\",\n",
    "    mode=\"min\",\n",
    "    perturbation_interval=1,\n",
    "    hyperparam_mutations={\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 1e-1),\n",
    "        \"warmup_ratio\": tune.loguniform(1e-2, 1e-1),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5231a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import JupyterNotebookReporter\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    parameter_columns=[\n",
    "        \"weight_decay\",\n",
    "        \"learning_rate\",\n",
    "        \"warmup_ratio\",\n",
    "        \"per_device_train_batch_size\",\n",
    "        \"n_layer_and_heads\",\n",
    "        \"embed_dim\",\n",
    "    ],\n",
    "    metric_columns=[\"eval_loss\", \"epoch\", \"training_iteration\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d994af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "12 * 96 * math.exp(2 * 5.039) * math.exp(2 * (5.55e-2) * 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d44f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train import CheckpointConfig\n",
    "\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    hp_space=lambda _: tune_config,\n",
    "    backend=\"ray\",\n",
    "    n_trials=4,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
    "    scheduler=pbt_scheduler,\n",
    "    # checkpoint_config=CheckpointConfig(\n",
    "    #     num_to_keep=1,\n",
    "    #     checkpoint_score_attribute=\"training_iteration\",\n",
    "    # ),\n",
    "    progress_reporter=reporter,\n",
    "    local_dir=str(MODEL_LOGS_DIR),\n",
    "    name=\"tune_transformer_pbt\",\n",
    "    log_to_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b930024",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.run_summary.trial_dataframes[\"6b51c_00000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \"1_num_train_epochs=5\",\n",
    "    \"2_num_train_epochs=4\",\n",
    "    4,\n",
    "    4,\n",
    "    {\n",
    "        \"per_device_train_batch_size\": 32,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"num_train_epochs\": 4,\n",
    "        \"weight_decay\": 0.029992474745400864,\n",
    "        \"learning_rate\": 2.836995567863469e-05,\n",
    "    },\n",
    "    {\n",
    "        \"per_device_train_batch_size\": 16,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"num_train_epochs\": 4,\n",
    "        \"weight_decay\": 0.006175348288740734,\n",
    "        \"learning_rate\": 2.2695964542907755e-05,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59062d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomGPT2LMHeadModel.from_pretrained(FINAL_MODEL_DIR)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dded235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"left\"\n",
    "inference_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "batch = inference_data_collator(\n",
    "    encoded_dataset[\"test\"][:2],\n",
    ")\n",
    "batch = {k: v.to(\"cuda\") for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7313b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = model.generate(**batch).cpu()\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = [\n",
    "    [\n",
    "        token\n",
    "        for token in tokenizer.convert_ids_to_tokens(ids)\n",
    "        if token != tokenizer.pad_token\n",
    "    ]\n",
    "    for ids in output_ids\n",
    "]\n",
    "output_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
