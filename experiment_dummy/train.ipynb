{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ba9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# log = logging.getLogger()\n",
    "# log.handlers.clear()\n",
    "# log.addHandler(logging.StreamHandler())\n",
    "# log.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from medcat.cat import CAT\n",
    "# from foresight.models.lucid_transformers import LucidLM2HF\n",
    "from transformers import SchedulerType, Trainer, TrainingArguments\n",
    "\n",
    "# from medcat.cdb import CDB\n",
    "from foresight.datasets.data_collator import CollataAndPad\n",
    "from foresight.datasets.data_collator_v2 import (\n",
    "    DataCollatorForLanguageModelingMaskStaticVariables,\n",
    ")\n",
    "from foresight.metrics.next_concept_prediction import (\n",
    "    ComputePrecisionHF,\n",
    "    metrics_data2df,\n",
    "    precision,\n",
    ")\n",
    "from foresight.models.custom_GPT2 import CustomGPT2Config, CustomGPT2LMHeadModel\n",
    "from foresight.tokenizers import PreTrainedTokenizerFastWithPositionIDPadding\n",
    "from foresight.tokenizers.simple_map_tokenizer import SimpleMapTokenizer\n",
    "from foresight.utils import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394581c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path.cwd() / \"outputs\"\n",
    "SAVE_TOKENIZER_PATH = OUTPUT_DIR / \"tokenizer\"\n",
    "SAVE_ENCODED_DATASET_PATH = OUTPUT_DIR / \"encoded_dataset\"\n",
    "MODEL_LOGS_DIR = OUTPUT_DIR / \"model_logs\" / time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "FINAL_MODEL_DIR = MODEL_LOGS_DIR / \"final_model\"\n",
    "\n",
    "\n",
    "NUM_STATIC_VARIABLES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = datasets.load_from_disk(SAVE_ENCODED_DATASET_PATH)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFastWithPositionIDPadding.from_pretrained(\n",
    "    SAVE_TOKENIZER_PATH\n",
    ")\n",
    "training_data_collator = DataCollatorForLanguageModelingMaskStaticVariables(\n",
    "    tokenizer=tokenizer, mlm=False, num_static_variables=NUM_STATIC_VARIABLES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d394ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DataLoader(\n",
    "    encoded_dataset[\"train\"],\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    "    collate_fn=training_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22d32c",
   "metadata": {},
   "source": [
    "# Create GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new model\n",
    "config = CustomGPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=100,\n",
    "    n_embd=16,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    bos_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.pad_token_id,\n",
    "    sep_token_id=tokenizer.sep_token_id,\n",
    ")\n",
    "model = CustomGPT2LMHeadModel(config)\n",
    "model.generation_config.max_length = 100\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7303e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113550ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**next(iter(dataset_train))).logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ee1ea",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e17497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_metrics = ComputePrecisionHF(tokenizer.id2tkn,\n",
    "#                                      prediction_scope='time_range',\n",
    "#                                      topk=1,\n",
    "#                                      start=0,\n",
    "#                                      return_all_metrics=False,\n",
    "#                                      batch_size=1000,\n",
    "#                                      select_token_types=all_types,\n",
    "#                                      type_data=test_set_to_use['token_type'],\n",
    "#                                      token_type2tokens=tokenizer.token_type2tokens,\n",
    "#                                      time_data=test_set_to_use['time'],\n",
    "#                                      time_range=30*24*60*60,\n",
    "#                                      ignore_label_status=False,\n",
    "#                                      min_time_left=24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44218b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foresight.metrics.timeline import TimelineMetrics\n",
    "\n",
    "timeline_metrics = TimelineMetrics(tokenizer)\n",
    "compute_metrics = lambda eval_preds: timeline_metrics.compute_micro_precision_recall_f1(\n",
    "    eval_preds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_LOGS_DIR,  # output directory\n",
    "    num_train_epochs=20,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    # weight_decay=1e-2,               # strength of weight decay\n",
    "    # logging_dir='./logs',            # directory for storing logs\n",
    "    # warmup_ratio=0.01,\n",
    "    learning_rate=2e-03,\n",
    "    # eval_accumulation_steps=1,\n",
    "    # gradient_accumulation_steps=16,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    # lr_scheduler_type=SchedulerType.LINEAR,\n",
    "    # use_cpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project='timecat', entity='wish', name=RUN_NAME + '-gpt-16-16_1day_no_base_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=encoded_dataset[\"train\"],  # training dataset\n",
    "    eval_dataset=encoded_dataset[\"test\"],  # evaluation dataset\n",
    "    # compute_metrics=compute_metrics,\n",
    "    data_collator=training_data_collator,\n",
    "    # prediction_loss_only=True\n",
    "    # tokenizer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n",
    "# trainer.save_model(FINAL_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59062d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CustomGPT2LMHeadModel.from_pretrained(FINAL_MODEL_DIR)\n",
    "model = CustomGPT2LMHeadModel.from_pretrained(\n",
    "    \"./outputs/model_logs/2024_02_07_16_18_57/final_model\"\n",
    ")\n",
    "# model.to(\"cuda\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_collator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801544bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {k: torch.tensor([v]) for k, v in encoded_dataset[\"test\"][0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dded235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "inference_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = inference_data_collator(\n",
    "    encoded_dataset[\"test\"][:2],\n",
    ")\n",
    "print([(k, v.shape) for k, v in batch.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mask = (batch[\"input_ids\"] == tokenizer.sep_token_id).long()\n",
    "sep_count = sep_mask.cumsum(-1) - sep_mask\n",
    "sep_count[batch[\"input_ids\"] == tokenizer.sep_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7313b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = model.generate(**batch)\n",
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(output_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14763dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = torch.argmax(logits.logits, dim=-1)\n",
    "pred_labels.shape\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835488c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**(encoded_dataset[\"test\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f6a43",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import PopulationBasedTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = ComputePrecisionHF(\n",
    "    id2tkn, id2type, prediction_scope=\"age\", topk=1, start=0, batch_size=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 20\n",
    "N_GPU_PER_TRIAL = 1\n",
    "METRIC_TO_OPTIMIZE = \"eval_precision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27783bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    torch.cuda.empty_cache()\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    config = GPT2Config(\n",
    "        vocab_size=len(embeddings),\n",
    "        n_positions=MAX_SEQ_LEN + 1,\n",
    "        n_ctx=MAX_SEQ_LEN + 1,\n",
    "        n_embd=params.get(\"n_embd\", 300),\n",
    "        n_layer=params.get(\"n_layer\", 1),\n",
    "        n_head=params.get(\"n_head\", 1),\n",
    "        bos_token_id=tkn2id[\"<PAD>\"],\n",
    "        eos_token_id=tkn2id[\"<PAD>\"],\n",
    "    )\n",
    "    model = GPT2LMHeadModel(config)\n",
    "\n",
    "    if params.get(\"load_weights\", 0):\n",
    "        model.transformer.wte.load_state_dict(\n",
    "            {\"weight\": torch.tensor(embeddings, dtype=torch.float32)}\n",
    "        )\n",
    "        model.transformer.wte.weight.requires_grad = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # output directory\n",
    "    num_train_epochs=5,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=128,  # batch size for evaluation\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=\"./logs\",  # directory for storing logs\n",
    "    logging_steps=200,\n",
    "    eval_steps=200,\n",
    "    learning_rate=5e-5,\n",
    "    eval_accumulation_steps=1,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    skip_memory_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.n_head = 1\n",
    "training_args.n_layer = 1\n",
    "training_args.n_embd = 300\n",
    "training_args.load_weights = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_dataset = encoded_dataset[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f111f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_train_dataset = tune_dataset[\"train\"]\n",
    "tune_test_dataset = tune_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    #    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=tune_train_dataset,  # training dataset\n",
    "    eval_dataset=tune_test_dataset,  # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    "    model_init=get_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0356cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_config = {\n",
    "    \"num_train_epochs\": tune.choice([5]),\n",
    "    \"n_head\": tune.choice([2, 4, 6]),\n",
    "}\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=METRIC_TO_OPTIMIZE,\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=1,\n",
    "    hyperparam_mutations={\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
    "        \"per_device_train_batch_size\": [16, 32, 64, 128],\n",
    "        \"n_layer\": tune.choice([2, 4, 6, 8]),\n",
    "        #       \"n_embd\": tune.choice([256, 512]),\n",
    "        \"load_weights\": tune.choice([0, 1]),\n",
    "        \"warmup_steps\": tune.choice([20, 40, 60, 100]),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def compute_objective(metrics):\n",
    "    metrics = copy.deepcopy(metrics)\n",
    "    eval_precision = metrics.pop(\"eval_precision\")\n",
    "\n",
    "    return eval_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trainer.hyperparameter_search(\n",
    "    hp_space=lambda _: tune_config,\n",
    "    backend=\"ray\",\n",
    "    n_trials=NUM_TRIALS,\n",
    "    direction=\"maximize\",\n",
    "    compute_objective=compute_objective,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": N_GPU_PER_TRIAL},\n",
    "    scheduler=scheduler,\n",
    "    keep_checkpoints_num=1,\n",
    "    checkpoint_score_attr=METRIC_TO_OPTIMIZE,\n",
    "    stop=None,\n",
    "    local_dir=RESULTS_HYPERPARAM,\n",
    "    name=\"21_May_2021\",\n",
    "    log_to_file=False,\n",
    "    loggers=None,  # (WandbLogger, ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3fae5",
   "metadata": {},
   "source": [
    "# Saliency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b237de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ecco.LM(trainer.model, tokenizer, model_name=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 49\n",
    "print(\n",
    "    \"~~\".join(\n",
    "        [tokenizer.id2tkn[id] for id in encoded_dataset[\"test\"][ind][\"input_ids\"]]\n",
    "    )\n",
    ")\n",
    "text = \"~~\".join(\n",
    "    [tokenizer.id2tkn[id] for id in encoded_dataset[\"test\"][ind][\"input_ids\"][1:-1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28108d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lm.generate(text, generate=10, do_sample=True, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.saliency(style=\"detailed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb6cf5",
   "metadata": {},
   "source": [
    "# Probability prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foresight.sight import Sight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sight = Sight(tokenizer=tokenizer, device=\"cuda\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb.name2cuis[\"muscle~pain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb.get_name(\"pain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<ETHNICITY>~~White~~<SEX>~~Male~~<AGE>~~23~~49727002~~386661006\".split(\"~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small with WD\n",
    "r = sight.next_concepts(\n",
    "    text, type_ids=[\"T-11\"], n=40, p_new=True, create_position_ids=False\n",
    ")\n",
    "print([cdb.get_name(x) for x in text])\n",
    "for x in r:\n",
    "    print(x[0], x[1], cdb.get_name(x[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
